import argparse
import os

import requests
from bs4 import BeautifulSoup
import psycopg2


def get_connection(db_name):
    conn_string = f"dbname={db_name}"
    conn = psycopg2.connect(conn_string)
    return conn
    

def parse_args():
    parser = argparse.ArgumentParser(description='Lyrics crawler')
    parser.add_argument("--db", default="lyrics", help='Name of database to use')
    parser.add_argument("--fl", help='First letter of artist')
    parser.add_argument("command", choices=["init", "crawl"])
    return parser.parse_args()


def download_lyrics(url):
    resp = requests.get(url)
    soup = BeautifulSoup(resp.content, features="html.parser")
    lyrics_div = soup.find("p", {"id": "songLyricsDiv"})
    lyrics = lyrics_div.text
    return lyrics
    

def get_popular_songs(artist):
    links = []
    resp = requests.get(artist)
    soup = BeautifulSoup(resp.content, features="html.parser")
    table = soup.find("table", {"class" : "tracklist"})
    for link in table.find_all("a"):
        text = link.text
        url = link['href']
        links.append((text, url))
    return links
    

def get_all_artists(fl, base_url="https://www.songlyrics.com/"):
    base_url = base_url+fl+"/"
    links = []
    resp = requests.get(base_url)
    soup = BeautifulSoup(resp.content, features="html.parser")
    table = soup.find("table", {"class" : "tracklist"})
    for link in table.find_all("a"):
        text = link.text
        url = link['href']
        links.append((text, url))
    return links


def insert_or_create_artist(conn, name):
    curs = conn.cursor()
    q1 = "SELECT id from artist where name=%s"
    curs.execute(q1, (name,))
    artist_id = curs.fetchone()
    if not artist_id:
        q2 = "INSERT INTO artist(name) VALUES (%s)"
        curs.execute(q2, (name,))
        q1 = "SELECT id from artist where name=%s"
        curs.execute(q1, (name,))
        artist_id  = curs.fetchone()
    return (artist_id[0])

def insert_lyrics(conn, artist_id, name, lyrics):
    curs = conn.cursor()
    q1 = "INSERT INTO song(artist, name, lyrics) VALUES(%s, %s, %s)"
    curs.execute(q1, (artist_id, name, lyrics))
    

def crawl(args):
    conn = get_connection(args.db)

    artists = get_all_artists(args.fl)
    for name, url in artists:
        name = name[:50]
        artist_id = insert_or_create_artist(conn, name)
        songs = get_popular_songs(url)
        nsongs = len(songs)
        c = 1
        for song_name, song_link  in songs:
            print (f"{name} {c}/{nsongs}\r", end="", flush=True)
            c = c + 1
            lyrics = download_lyrics(song_link)
            insert_lyrics(conn, artist_id, song_name, lyrics)
        conn.commit()
        print (f"{name} DONE")
        

def init_db(args):
    conn = get_connection(args.db)
    cur = conn.cursor()
    cur.execute("DROP TABLE IF EXISTS song")
    cur.execute("DROP TABLE IF EXISTS artist")

    cur.execute("""CREATE TABLE artist (
id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
name VARCHAR(50))""")

    cur.execute("""CREATE TABLE song (
id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
artist INTEGER references artist(id),
name VARCHAR(100),
lyrics TEXT)""")
    conn.commit()
    


def main(args):
    if args.command == "init":
        print ("Initialising database")
        init_db(args)
        print ("Done")
    elif args.command == "crawl":
        print ("Crawling for lyrics")
        crawl(args)

if __name__ == "__main__":
    args = parse_args()
    main(args)
    



    
